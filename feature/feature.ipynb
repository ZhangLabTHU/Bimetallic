{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase.db\n",
    "from ase import atoms\n",
    "from ase.io import read\n",
    "import numpy as np\n",
    "from ase import Atom,Atoms\n",
    "from ase.neighborlist import NeighborList\n",
    "from mendeleev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ase.db.connect('../../Database/g6/ptag.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract neighborlist based on pure.traj\n",
    "atoms = read('pure.traj')\n",
    "radius = [1.5]*64 # set 1.5 to make sure surf atoms have 10 neighbors and bulk atoms have 14 neighbors.  \n",
    "nl = NeighborList(radius, self_interaction=False, bothways=True)\n",
    "nl.update(atoms)\n",
    "# neighbor store the neighbor atoms index in PdAu.\n",
    "neighbor_list = {}\n",
    "coordination_list = {}\n",
    "adsorption_list = {}\n",
    "for index in range(len(atoms)):\n",
    "    indices, offsets = nl.get_neighbors(index)\n",
    "    indices = indices.tolist()\n",
    "    neighbor_list[index] = indices \n",
    "    coordination_list[index] = len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract adsorptionlist based on pure.traj\n",
    "# adsorption_list保存每一个位点对应的三层shell\n",
    "adsorption_coordination_list = {} #按照配位数划分\n",
    "\n",
    "# 读取pure.traj，扩展3倍\n",
    "atoms = read('pure.traj') \n",
    "extend_atoms = atoms*[3,3,1]\n",
    "\n",
    "# fcc_indices记录扩胞后16个组成fcc位点的3个原子标号\n",
    "fcc_indices = [[268,270,269],[270,300,271],[300,302,301],[302,460,303],\n",
    "              [269,271,284],[271,301,286],[301,303,316],[303,461,318],\n",
    "              [284,286,285],[286,316,287],[316,318,317],[318,319,476],\n",
    "              [285,287,332],[287,317,334],[317,319,364],[319,477,366]]\n",
    "\n",
    "# 通过近邻判断原子数\n",
    "radius = [1.5]*576 # set 1.5 to make sure surf atoms have 10 neighbors and bulk atoms have 14 neighbors.  \n",
    "nl = NeighborList(radius, self_interaction=False, bothways=True)\n",
    "nl.update(extend_atoms)\n",
    "neighbor_extend_list = {}\n",
    "coordination_extend_list ={}\n",
    "for index in range(len(extend_atoms)):\n",
    "    indices, offsets = nl.get_neighbors(index)\n",
    "    indices = indices.tolist()\n",
    "    neighbor_extend_list[index] = indices\n",
    "    coordination_extend_list[index] = len(indices)\n",
    "\n",
    "# 每一个fcc位点划分6层特征，6层原子数分别为3，3，3，6，3，40\n",
    "for num in range(16):\n",
    "    first_shell = fcc_indices[num]\n",
    "    \n",
    "    second_shell = []\n",
    "    for i in first_shell:\n",
    "        neighbor_i = neighbor_extend_list[i]\n",
    "        for j in neighbor_i:\n",
    "            if j not in first_shell and j not in second_shell:\n",
    "                second_shell.append(j)\n",
    "    \n",
    "    third_shell = []\n",
    "    for i in second_shell:\n",
    "        neighbor_i = neighbor_extend_list[i]\n",
    "        for j in neighbor_i:\n",
    "            if j not in second_shell and j not in third_shell:\n",
    "                third_shell.append(j)\n",
    "    \n",
    "    # divide second shell into three sub shells by distance\n",
    "    position1 = extend_atoms[first_shell[0]].position+[0,0,1.2]\n",
    "    position2 = extend_atoms[first_shell[1]].position+[0,0,1.2]\n",
    "    position3 = extend_atoms[first_shell[2]].position+[0,0,1.2]\n",
    "    center_position = (position1+position2+position3)/3\n",
    "    second_shell_distance = {}\n",
    "    for index in second_shell:\n",
    "        second_shell_distance[index] = np.linalg.norm(center_position-extend_atoms[index].position)\n",
    "    second_shell_distance_ordered = sorted(second_shell_distance.items(), key=lambda item:item[1])\n",
    "    second_shell_distance_sub1 = [second_shell_distance_ordered[i][0] for i in range(0,3)] \n",
    "    second_shell_distance_sub2 = [second_shell_distance_ordered[i][0] for i in range(3,6)]\n",
    "    second_shell_distance_sub3 = [second_shell_distance_ordered[i][0] for i in range(6,12)]\n",
    "    second_shell_distance_sub4 = [second_shell_distance_ordered[i][0] for i in range(12,15)]\n",
    "    \n",
    "    adsorption_shell = []\n",
    "    adsorption_shell.append([i%64 for i in first_shell])\n",
    "    adsorption_shell.append([i%64 for i in second_shell_distance_sub1])\n",
    "    adsorption_shell.append([i%64 for i in second_shell_distance_sub2])\n",
    "    adsorption_shell.append([i%64 for i in second_shell_distance_sub3])\n",
    "    adsorption_shell.append([i%64 for i in second_shell_distance_sub4])\n",
    "    adsorption_coordination_list[num] = adsorption_shell\n",
    "\n",
    "neighbor_multi_list = []\n",
    "for i in range(5*64,6*64):\n",
    "    neigh_i_dict = {}\n",
    "    first_shell_i = neighbor_extend_list[i].copy()\n",
    "    total_shell_i = first_shell_i.copy()\n",
    "    \n",
    "    second_shell_i = []\n",
    "    for j in first_shell_i:\n",
    "        shell_ij = neighbor_extend_list[j].copy()\n",
    "        for k in shell_ij:\n",
    "            if (k not in total_shell_i) and (k not in second_shell_i):\n",
    "                second_shell_i.append(k)\n",
    "                total_shell_i.append(k)\n",
    "            elif k not in total_shell_i:\n",
    "                total_shell_i.append(k)\n",
    "    \n",
    "    third_shell_i = []\n",
    "    for j in second_shell_i:\n",
    "        shell_ij = neighbor_extend_list[j].copy()\n",
    "        for k in shell_ij:\n",
    "            if (k not in total_shell_i) and (k not in third_shell_i):\n",
    "                third_shell_i.append(k)\n",
    "                total_shell_i.append(k)\n",
    "            elif k not in total_shell_i:\n",
    "                total_shell_i.append(k)\n",
    "\n",
    "    fourth_shell_i = []\n",
    "    for j in third_shell_i:\n",
    "        shell_ij = neighbor_extend_list[j].copy()\n",
    "        for k in shell_ij:\n",
    "            if (k not in total_shell_i) and (k not in fourth_shell_i):\n",
    "                fourth_shell_i.append(k)\n",
    "                total_shell_i.append(k)\n",
    "            elif k not in total_shell_i:\n",
    "                total_shell_i.append(k)\n",
    "    \n",
    "    fifth_shell_i = []\n",
    "    for j in fourth_shell_i:\n",
    "        shell_ij = neighbor_extend_list[j].copy()\n",
    "        for k in shell_ij:\n",
    "            if (k not in total_shell_i) and (k not in fifth_shell_i):\n",
    "                fifth_shell_i.append(k)\n",
    "                total_shell_i.append(k)\n",
    "            elif k not in total_shell_i:\n",
    "                total_shell_i.append(k)\n",
    "    \n",
    "    neigh_i_dict[1] = [i%64 for i in first_shell_i.copy()]\n",
    "    #print('first shell:',len(first_shell_i))\n",
    "    neigh_i_dict[2] = [i%64 for i in second_shell_i.copy()]\n",
    "    #print('second shell:',len(second_shell_i))\n",
    "    neigh_i_dict[3] = [i%64 for i in third_shell_i.copy()]\n",
    "    #print('third shell:',len(third_shell_i))\n",
    "    neigh_i_dict[4] = [i%64 for i in fourth_shell_i.copy()]\n",
    "    #print('fourth shell:',len(fourth_shell_i))\n",
    "    neigh_i_dict[5] = [i%64 for i in fifth_shell_i.copy()]\n",
    "    neighbor_multi_list.append(neigh_i_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_list(list_target, shell_pd, shell_coord_pd, shell_au, shell_coord_au):\n",
    "    if len(shell_pd) !=0:\n",
    "        list_target.append(len(shell_pd))\n",
    "        list_target.append(np.mean(shell_coord_pd))\n",
    "    else:\n",
    "        list_target.append(0)\n",
    "        list_target.append(0)\n",
    "\n",
    "    if len(shell_au) !=0:\n",
    "        list_target.append(len(shell_au))   # number  \n",
    "        list_target.append(np.mean(shell_coord_au)) # mean of coordination number \n",
    "\n",
    "    else:\n",
    "        list_target.append(0)\n",
    "        list_target.append(0)\n",
    "        \n",
    "    return list_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract ads feature from ptni.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "8\n",
      "9\n",
      "10\n",
      "12\n",
      "13\n",
      "14\n",
      "16\n",
      "17\n",
      "18\n",
      "20\n",
      "21\n",
      "22\n",
      "24\n",
      "25\n",
      "26\n",
      "28\n",
      "29\n",
      "30\n",
      "32\n",
      "34\n",
      "35\n",
      "36\n",
      "38\n",
      "39\n",
      "40\n",
      "42\n",
      "43\n",
      "44\n",
      "46\n",
      "47\n",
      "48\n",
      "50\n",
      "51\n",
      "52\n",
      "54\n",
      "55\n",
      "57\n",
      "58\n",
      "59\n",
      "61\n",
      "62\n",
      "63\n",
      "65\n",
      "66\n",
      "67\n",
      "69\n",
      "70\n",
      "71\n",
      "73\n",
      "74\n",
      "75\n",
      "77\n",
      "78\n",
      "79\n",
      "81\n",
      "82\n",
      "83\n",
      "85\n",
      "86\n",
      "87\n",
      "89\n",
      "90\n",
      "91\n",
      "93\n",
      "94\n",
      "95\n",
      "97\n",
      "98\n",
      "99\n",
      "101\n",
      "102\n",
      "103\n",
      "106\n",
      "107\n",
      "109\n",
      "110\n",
      "111\n",
      "113\n",
      "114\n",
      "115\n",
      "117\n",
      "118\n",
      "119\n",
      "121\n",
      "122\n",
      "123\n",
      "125\n",
      "126\n",
      "127\n",
      "129\n",
      "130\n",
      "131\n",
      "133\n",
      "134\n",
      "135\n",
      "137\n",
      "138\n",
      "139\n",
      "141\n",
      "142\n",
      "143\n",
      "146\n",
      "147\n",
      "149\n",
      "150\n",
      "151\n",
      "153\n",
      "154\n",
      "155\n",
      "157\n",
      "158\n",
      "159\n",
      "161\n",
      "162\n",
      "163\n",
      "165\n",
      "166\n",
      "167\n",
      "169\n",
      "170\n",
      "171\n",
      "173\n",
      "174\n",
      "175\n",
      "177\n",
      "178\n",
      "179\n",
      "181\n",
      "182\n",
      "183\n",
      "185\n",
      "186\n",
      "187\n",
      "189\n",
      "190\n",
      "191\n",
      "193\n",
      "194\n",
      "195\n",
      "197\n",
      "198\n",
      "199\n",
      "201\n",
      "202\n",
      "203\n",
      "205\n",
      "206\n",
      "207\n",
      "209\n",
      "210\n",
      "211\n",
      "213\n",
      "214\n",
      "215\n",
      "217\n",
      "218\n",
      "219\n"
     ]
    }
   ],
   "source": [
    "Adsorption_coordination_feature = []\n",
    "Ratio = []\n",
    "Ads_energy = []\n",
    "Feature = []\n",
    "Index = []\n",
    "Sro = []\n",
    "Label = []\n",
    "Activity= []\n",
    "\n",
    "\n",
    "for row in db.select(jobtype='ads',status='relaxed'):\n",
    "    print(row.id)\n",
    "    sid = row.sid\n",
    "    begin_index = sid.find('0x')\n",
    "    config_code = sid[begin_index:-3]\n",
    "    config_str = '{:064b}'.format(int(config_code,16))\n",
    "    config_int = [int(i) for i in config_str]\n",
    "    au_atom_list = [i for i,x in enumerate(config_int) if x==1]\n",
    "   \n",
    "    first_shell = [int(row.uid[-3:]),int(row.uid[-6:-3]),int(row.uid[-9:-6])]\n",
    "    for i in range(16):\n",
    "        if sorted(adsorption_coordination_list[i][0]) == sorted(first_shell):\n",
    "            fcc_index = i\n",
    "            break\n",
    "    \n",
    "    adsorption_coordination_feature = []\n",
    "    for j in range(5):\n",
    "        shell = adsorption_coordination_list[fcc_index][j]\n",
    "        shell_pd = [k for k in shell if k not in au_atom_list]\n",
    "        shell_pd_coord = [coordination_list[k] for k in shell_pd]\n",
    "        shell_au = [k for k in shell if k in au_atom_list]\n",
    "        shell_au_coord = [coordination_list[k] for k in shell_au]\n",
    "        adsorption_coordination_feature = add_to_list(adsorption_coordination_feature, shell_pd, shell_pd_coord, shell_au, shell_au_coord)\n",
    "            \n",
    "    atoms = db.get_atoms(id=row.id)\n",
    "    ratio = len(au_atom_list)/64\n",
    "    sur_energy = db.get(sid=row.sid,jobtype='sur').energy\n",
    "    ads_energy = row.energy\n",
    "    eo = ads_energy-sur_energy+7.46\n",
    "    if eo < 1.58:\n",
    "        activity = 0.600*(eo+0.23)-1.376\n",
    "    else:\n",
    "        activity = -1.645*(eo+0.23)+2.688\n",
    "    \n",
    "    Activity.append(activity)\n",
    "    Adsorption_coordination_feature.append(adsorption_coordination_feature)\n",
    "    Ratio.append(ratio)\n",
    "\n",
    "    feature =adsorption_coordination_feature + [ratio]\n",
    "    Feature.append(feature)\n",
    "    Index.append(row.id)\n",
    "    Ads_energy.append(eo)\n",
    "    \n",
    "np.savetxt('ratio.csv',Ratio,delimiter=',')\n",
    "np.savetxt('activity.csv',Activity,delimiter=',')\n",
    "np.savetxt('energy.csv',Ads_energy,delimiter=',')\n",
    "np.savetxt('ptag_feature.csv',Feature,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract all sites feature from ptco.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "7\n",
      "11\n",
      "15\n",
      "19\n",
      "23\n",
      "27\n",
      "31\n",
      "33\n",
      "37\n",
      "41\n",
      "45\n",
      "49\n",
      "53\n",
      "56\n",
      "60\n",
      "64\n",
      "68\n",
      "72\n",
      "76\n",
      "80\n",
      "84\n",
      "88\n",
      "92\n",
      "96\n",
      "100\n",
      "104\n",
      "108\n",
      "112\n",
      "116\n",
      "120\n",
      "124\n",
      "128\n",
      "132\n",
      "136\n",
      "140\n",
      "144\n",
      "148\n",
      "152\n",
      "156\n",
      "160\n",
      "164\n",
      "168\n",
      "172\n",
      "176\n",
      "180\n",
      "184\n",
      "188\n",
      "192\n",
      "196\n",
      "200\n",
      "204\n",
      "208\n",
      "212\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "Global_feature = []\n",
    "Adsorption_feature = []\n",
    "Ratio = []\n",
    "Strain = []\n",
    "Ads_energy = []\n",
    "Feature = []\n",
    "Index = []\n",
    "Bop = []\n",
    "Label = []\n",
    "Activity= []\n",
    "\n",
    "for row in db.select(jobtype='sur',status='relaxed'):\n",
    "    print(row.id)\n",
    "    sid = row.sid\n",
    "    begin_index = sid.find('0x')\n",
    "    config_code = sid[begin_index:-3]\n",
    "    config_str = '{:064b}'.format(int(config_code,16))\n",
    "    config_int = [int(i) for i in config_str]\n",
    "    au_atom_list = [i for i,x in enumerate(config_int) if x==1]\n",
    "    \n",
    "    ratio = len(au_atom_list)/64\n",
    "    for i in range(16):\n",
    "        adsorption_coordination_feature = []\n",
    "        for j in range(5):\n",
    "            shell = adsorption_coordination_list[i][j]\n",
    "            shell_pd = [k for k in shell if k not in au_atom_list]\n",
    "            shell_pd_coord = [coordination_list[k] for k in shell_pd]\n",
    "            shell_au = [k for k in shell if k in au_atom_list]\n",
    "            shell_au_coord = [coordination_list[k] for k in shell_au]\n",
    "            adsorption_coordination_feature = add_to_list(adsorption_coordination_feature, shell_pd, shell_pd_coord, shell_au, shell_au_coord)\n",
    "        feature = adsorption_coordination_feature + [ratio]\n",
    "        Ratio.append(ratio)\n",
    "        Feature.append(feature)\n",
    "np.savetxt('ratio_all_sites.csv',Ratio,delimiter=',')\n",
    "np.savetxt('ptag_feature_all_sites.csv',Feature,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
